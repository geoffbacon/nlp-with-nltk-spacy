{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "NLTK is a large collection of NLP tools.We won't have time to cover everything, so we'll focus on the most common tools:\n",
    "\n",
    "[Existing corpora](#existing)<br>\n",
    "\n",
    "[Tokenization](#tokenization)<br>\n",
    "\n",
    "[Sentence segmentation](#sent-seg)<br>\n",
    "\n",
    "[Collocations](#collocations)<br>\n",
    "\n",
    "[Sentiment analysis](#sentiment)<br>\n",
    "\n",
    "[Stemming](#stemming)<br>\n",
    "\n",
    "[What we didn't cover](#didnt)<br>\n",
    "\n",
    "### Time\n",
    "- Teaching: 30 minutes\n",
    "- Exercises: 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing corpora <a id='existing'></a>\n",
    "\n",
    "When you downloaded data from nltk using `nltk.download('all')`, you downloaded a whole bunch of great corpora (collections of text documents) and lexical resources (structured information about words). This gives us data to work with already! If you ever want to learn/practice an NLP method, know that just by importing nltk you have access to some data. Here are some corpora and resources that are particularly useful and that we'll use throughout this workshop:\n",
    "\n",
    "- ABC\n",
    "- Brown\n",
    "- CMU pronunciation dictionary\n",
    "- Genesis\n",
    "- Project Gutenberg selections\n",
    "- Inaugural addresses\n",
    "- Movie reviews\n",
    "- Names\n",
    "- State of the Union addresses\n",
    "- Stopwords\n",
    "- Twitter samples\n",
    "- Universal Declaration of Human Rights\n",
    "- WordNet\n",
    "\n",
    "Full list of data in NLTK [here](http://www.nltk.org/nltk_data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import (abc, brown, cmudict, genesis, gutenberg,\n",
    "                         inaugural, movie_reviews, names, state_union, \n",
    "                         stopwords, swadesh, twitter_samples, udhr2, \n",
    "                         wordnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpora in NLTK are special objects in NLTK that give you the exact data you want only when you ask for it. For example, `brown` is not a string or a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CategorizedTaggedCorpusReader in '/Users/bacon/nltk_data/corpora/brown'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words, raw, sents, fileids\n",
    "\n",
    "But if I wanted the Brown corpus as a list of words, I could ask for it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if I wanted the text of the ABC corpus as a string, I could get it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PM denies knowledge of AWB kickbacks\\nThe Prime Minister has denied he knew AWB was paying kickbacks '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.raw()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted the sentences of a corpus, you can ask for them like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.'], ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These corpora are often made up of multiple files. You can see the file names by using the `fileids` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restrict the words, raw or sents to just the words/raw/sents in a particular file, you can list the file name as an optional argument to the `words`/`raw`/`sents` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aamir',\n",
       " 'Aaron',\n",
       " 'Abbey',\n",
       " 'Abbie',\n",
       " 'Abbot',\n",
       " 'Abbott',\n",
       " 'Abby',\n",
       " 'Abdel',\n",
       " 'Abdul',\n",
       " 'Abdulkarim']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_names = names.words('male.txt')\n",
    "male_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique properties\n",
    "\n",
    "Some corpora have unique aspects to them. For example, the CMU pronunciation dictionary lists (some standard) pronunciation of English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciation = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HH', 'AH0', 'L', 'OW1'], ['HH', 'EH0', 'L', 'OW1']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciation['hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Male vs. female names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6UAAAHbCAYAAAAzljzeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111c674e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def last_letter(name):\n",
    "    \"\"\"Returns the last letter of `name`.\"\"\"\n",
    "    return name.strip()[-1]\n",
    "\n",
    "def count_letters(names):\n",
    "    \"\"\"Returns the distribution of the last letters in `names`.\"\"\"\n",
    "    return pd.Series([last_letter(n) for n in names]).value_counts(normalize=True)\n",
    "\n",
    "def letter_distribution():\n",
    "    male_value_counts = count_letters(male_names)\n",
    "    female_value_counts = count_letters(female_names)\n",
    "    return pd.DataFrame.from_dict({'male': male_value_counts, 'female': female_value_counts})\n",
    "\n",
    "df = letter_distribution()\n",
    "df.plot(kind='bar', figsize=(16, 8))\n",
    "plt.legend(prop={'size': 20})\n",
    "plt.xticks(rotation=0, size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "- Count the lengths of the sentences (i.e. the number of words per sentence) in the `inaugural` corpus. Find the minimum, average and maximum sentence length.\n",
    "- Visualize the distribution of lengths.\n",
    "- Count the number of times the following words appear in the corpus: \"america\", \"citizen\", \"united\", \"senate\" and \"freedom\".\n",
    "- If you are surprised by anything in the answer to the last question, think about capitalization issues. Make all words lowercase and then perform your counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 29.9373459326212 810\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "lengths = [len(s) for s in inaugural.sents()]\n",
    "min_length = min(lengths)\n",
    "mean_length = sum(lengths) / len(lengths)\n",
    "max_length = max(lengths)\n",
    "print(min_length, mean_length, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD3CAYAAADxJYRbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111c569b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# solution\n",
    "sns.distplot(lengths);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "america : 0\n",
      "citizen : 54\n",
      "united : 32\n",
      "senate : 4\n",
      "freedom : 174\n"
     ]
    }
   ],
   "source": [
    "for word in [\"america\", \"citizen\", \"united\", \"senate\", \"freedom\"]:\n",
    "    n = inaugural.words().count(word)\n",
    "    print(word, ':', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "america : 192\n",
      "citizen : 54\n",
      "united : 197\n",
      "senate : 15\n",
      "freedom : 183\n"
     ]
    }
   ],
   "source": [
    "inaugural_words = [w.lower() for w in inaugural.words()]\n",
    "for word in [\"america\", \"citizen\", \"united\", \"senate\", \"freedom\"]:\n",
    "    n = inaugural_words.count(word)\n",
    "    print(word, ':', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization <a id='tokenization'></a>\n",
    "\n",
    "More often than not, you'll want to analyze some text that doesn't come from NLTK. Perhaps you've scraped a few websites and stored the text in a text file. One of the first steps in processing your text data is tokenization. **Tokenization refers to breaking a running string of text into individual words.**\n",
    "\n",
    "I've download the text contents of the Wikipedia page on [Python][1], and saved it in the `data` directory. We can read it in as follows:\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Python_(programming_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "python_wiki_fname = os.path.join(DATA_DIR, 'python_wikipedia.txt')\n",
    "with open(python_wiki_fname) as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `text` is a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is an interpreted high-level programming language for general-purpose programming. Created by'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tokenize this string by using nltk's `word_tokenize` function, which returns a list of strings. Each string is either a word or a punctuation symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interpreted',\n",
       " 'high-level',\n",
       " 'programming',\n",
       " 'language',\n",
       " 'for',\n",
       " 'general-purpose',\n",
       " 'programming']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses NLTK's recommended tokenizer. There are plenty of [other tokenizers in NLTK](https://github.com/nltk/nltk/tree/develop/nltk/tokenize), but unless you have good reason to do otherwise it's best to stick to the recommended tokenizer.\n",
    "\n",
    "### Challenge\n",
    "\n",
    "I've also downloaded the Wikipedia page for [Berkeley, California][2], and saved the contents as a file called 'berkeley_wikipedia.txt'. Borrowing from the code above, read this file in and tokenize the text. Then find the 10 most frequenct \"words\". After that, if you don't like counting punctuation symbols as \"words\", then remove all punctuation symbols then find the 10 most frequenct words.\n",
    "\n",
    "[2]: https://en.wikipedia.org/wiki/Berkeley,_California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",         406\n",
       ".         318\n",
       "the       212\n",
       "Python    203\n",
       "and       183\n",
       "a         155\n",
       "to        141\n",
       "of        139\n",
       "is        124\n",
       ")         110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "berkeley_wiki_fname = os.path.join(DATA_DIR, 'berkeley_wikipedia.txt')\n",
    "with open(python_wiki_fname) as f:\n",
    "    text = f.read()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "s = pd.Series(tokens)\n",
    "s.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the       212\n",
       "Python    203\n",
       "and       183\n",
       "a         155\n",
       "to        141\n",
       "of        139\n",
       "is        124\n",
       "in        109\n",
       "as         66\n",
       "for        65\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "no_punct = [t for t in tokens if t not in punctuation]\n",
    "s = pd.Series(no_punct)\n",
    "s.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence segmentation <a id='sent-seg'></a>\n",
    "\n",
    "Sentence segmentation refers to finding the beginnings and ends of sentences. It's also sometimes called sentence tokenization. Again, there are lots of ways in NLTK to do this, but they have conviently chosen a default method for us. The `nltk.sent_tokenize` function takes in a string and returns a list of strings, where each string is a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python is an interpreted high-level programming language for general-purpose programming.',\n",
       " 'Created by Guido van Rossum and first released in 1991, Python has a design philosophy that emphasizes code readability, notably using significant whitespace.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = nltk.sent_tokenize(text)\n",
    "sents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations <a id='collocations'></a>\n",
    "\n",
    "Collocations are words that frequently appear together. They can help us identify key phrases in a text. Collocations can be bigrams (two words), tri-grams (three) or 4-grams. In NLTK, we can use the `BigramCollocationFinder` to find all the bigram collocations in a text. First, we feed in the tokenized text. Here, we'll use the 'learned' portion of the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = brown.words(categories='learned')\n",
    "collocations = nltk.BigramCollocationFinder.from_words(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we decide which words to filter out. I don't want words less than three characters or stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_words = stopwords.words('english')\n",
    "word_filter = lambda w: len(w) < 3 or w.lower() in ignored_words\n",
    "collocations.apply_freq_filter(3)\n",
    "collocations.apply_word_filter(word_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we decide what method NLTK should use to decide what makes a collocation special. We'll use the likelihood ratio, which is a good standard choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('United', 'States'),\n",
       " ('per', 'cent'),\n",
       " ('dominant', 'stress'),\n",
       " ('carbon', 'tetrachloride'),\n",
       " ('sweet', 'clover'),\n",
       " ('wage', 'rate'),\n",
       " ('anode', 'holder'),\n",
       " ('electronic', 'switches'),\n",
       " ('John', 'Brown'),\n",
       " ('minimal', 'polynomial'),\n",
       " ('index', 'words'),\n",
       " ('index', 'word'),\n",
       " ('radio', 'emission'),\n",
       " ('pulmonary', 'artery'),\n",
       " ('electronic', 'switch')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = nltk.collocations.BigramAssocMeasures.likelihood_ratio\n",
    "collocations.nbest(scorer, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was kinda messy. We can wrap all this up into a nicer function that just takes in the tokens and spits out the collocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collocations(tokens):\n",
    "    collocations = nltk.BigramCollocationFinder.from_words(tokens)\n",
    "    ignored_words = stopwords.words('english')\n",
    "    word_filter = lambda w: len(w) < 3 or w.lower() in ignored_words\n",
    "    collocations.apply_freq_filter(3)\n",
    "    collocations.apply_word_filter(word_filter)\n",
    "    scorer = nltk.collocations.BigramAssocMeasures.likelihood_ratio\n",
    "    return collocations.nbest(scorer, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now run `my_collocations` on some new text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('United', 'States'),\n",
       " ('fiscal', 'year'),\n",
       " ('Social', 'Security'),\n",
       " ('American', 'people'),\n",
       " ('United', 'Nations'),\n",
       " ('million', 'dollars'),\n",
       " ('health', 'care'),\n",
       " ('billion', 'dollars'),\n",
       " ('Middle', 'East'),\n",
       " ('years', 'ago'),\n",
       " ('Federal', 'Government'),\n",
       " ('Soviet', 'Union'),\n",
       " ('21st', 'century'),\n",
       " ('last', 'year'),\n",
       " ('JOINT', 'SESSION')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_collocations(state_union.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Frank', 'Churchill'),\n",
       " ('Miss', 'Woodhouse'),\n",
       " ('Miss', 'Bates'),\n",
       " ('Jane', 'Fairfax'),\n",
       " ('Miss', 'Fairfax'),\n",
       " ('every', 'thing'),\n",
       " ('young', 'man'),\n",
       " ('every', 'body'),\n",
       " ('great', 'deal'),\n",
       " ('dare', 'say'),\n",
       " ('John', 'Knightley'),\n",
       " ('Maple', 'Grove'),\n",
       " ('Miss', 'Smith'),\n",
       " ('Miss', 'Taylor'),\n",
       " ('Robert', 'Martin')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = gutenberg.words('austen-emma.txt')\n",
    "my_collocations(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'unto'),\n",
       " ('pray', 'thee'),\n",
       " ('thou', 'shalt'),\n",
       " ('thou', 'hast'),\n",
       " ('thy', 'seed'),\n",
       " ('years', 'old'),\n",
       " ('spake', 'unto'),\n",
       " ('thou', 'art'),\n",
       " ('LORD', 'God'),\n",
       " ('every', 'living'),\n",
       " ('God', 'hath'),\n",
       " ('begat', 'sons'),\n",
       " ('seven', 'years'),\n",
       " ('shalt', 'thou'),\n",
       " ('little', 'ones')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_collocations(genesis.words('english-kjv.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis <a id='sentiment'></a>\n",
    "\n",
    "NLTK has support for sentiment analysis. [Sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) is the task of extracting [affective states](https://en.wikipedia.org/wiki/Affect_(psychology)) from text. The VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. There was a [Python package](https://github.com/cjhutto/vaderSentiment) developed for it outside of NLTK, which was then incorporated into NLTK. Loading it through NLTK is often buggy, but we can install the original package if it fails through NLTK. It ends up working the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis in NLTK is not working at the moment :(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "try:\n",
    "    sentiment = SentimentIntensityAnalyzer()\n",
    "except LookupError:\n",
    "    print('Sentiment analysis in NLTK is not working at the moment :(')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `SentimentIntensityAnalyzer` isn't loading properly from `nltk`, then you'll have to install the original package using the line below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: vaderSentiment in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then import it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether you used NLTK's `SentimentIntensityAnalyzer` or gor it from `vaderSentiment`, the rest of the code is identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing a sentence for its sentiment returns a dictionary with four items. The `compound` key holds the overall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.6837, 'neg': 0.374, 'neu': 0.461, 'pos': 0.165}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I hate this sentence so much. I just want it to end. It sucks!\"\n",
    "sentiment.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"VADER is smart, handsome, and funny.\",      # positive sentence example\n",
    "            \"VADER is not smart, handsome, nor funny.\",   # negation sentence example\n",
    "            \"VADER is smart, handsome, and funny!\",       # punctuation emphasis handled correctly (sentiment intensity adjusted)\n",
    "            \"VADER is very smart, handsome, and funny.\",  # booster words handled correctly (sentiment intensity adjusted)\n",
    "            \"VADER is VERY SMART, handsome, and FUNNY.\",  # emphasis for ALLCAPS handled\n",
    "            \"VADER is VERY SMART, handsome, and FUNNY!!!\",# combination of signals - VADER appropriately adjusts intensity\n",
    "            \"VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!\",# booster words & punctuation make this close to ceiling for score\n",
    "            \"The book was good.\",                                     # positive sentence\n",
    "            \"The book was kind of good.\",                 # qualified positive sentence is handled correctly (intensity adjusted)\n",
    "            \"The plot was good, but the characters are uncompelling and the dialog is not great.\", # mixed negation sentence\n",
    "            \"At least it isn't a horrible book.\",         # negated negative sentence with contraction\n",
    "            \"Make sure you :) or :D today!\",              # emoticons handled\n",
    "            \"Today SUX!\",                                 # negative slang with capitalization emphasis\n",
    "            \"Today only kinda sux! But I'll get by, lol\"  # mixed sentiment example with slang and constrastive conjunction \"but\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8316</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.746</td>\n",
       "      <td>VADER is smart, handsome, and funny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.7424</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>VADER is not smart, handsome, nor funny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.752</td>\n",
       "      <td>VADER is smart, handsome, and funny!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.701</td>\n",
       "      <td>VADER is very smart, handsome, and funny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.754</td>\n",
       "      <td>VADER is VERY SMART, handsome, and FUNNY.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>VADER is VERY SMART, handsome, and FUNNY!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9469</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.706</td>\n",
       "      <td>VADER is VERY SMART, uber handsome, and FRIGGI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.492</td>\n",
       "      <td>The book was good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3832</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.343</td>\n",
       "      <td>The book was kind of good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.7042</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.094</td>\n",
       "      <td>The plot was good, but the characters are unco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.363</td>\n",
       "      <td>At least it isn't a horrible book.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8633</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.706</td>\n",
       "      <td>Make sure you :) or :D today!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.5461</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Today SUX!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.251</td>\n",
       "      <td>Today only kinda sux! But I'll get by, lol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    compound    neg    neu    pos  \\\n",
       "0     0.8316  0.000  0.254  0.746   \n",
       "1    -0.7424  0.646  0.354  0.000   \n",
       "2     0.8439  0.000  0.248  0.752   \n",
       "3     0.8545  0.000  0.299  0.701   \n",
       "4     0.9227  0.000  0.246  0.754   \n",
       "5     0.9342  0.000  0.233  0.767   \n",
       "6     0.9469  0.000  0.294  0.706   \n",
       "7     0.4404  0.000  0.508  0.492   \n",
       "8     0.3832  0.000  0.657  0.343   \n",
       "9    -0.7042  0.327  0.579  0.094   \n",
       "10    0.4310  0.000  0.637  0.363   \n",
       "11    0.8633  0.000  0.294  0.706   \n",
       "12   -0.5461  0.779  0.221  0.000   \n",
       "13    0.2228  0.179  0.569  0.251   \n",
       "\n",
       "                                             sentence  \n",
       "0                VADER is smart, handsome, and funny.  \n",
       "1            VADER is not smart, handsome, nor funny.  \n",
       "2                VADER is smart, handsome, and funny!  \n",
       "3           VADER is very smart, handsome, and funny.  \n",
       "4           VADER is VERY SMART, handsome, and FUNNY.  \n",
       "5         VADER is VERY SMART, handsome, and FUNNY!!!  \n",
       "6   VADER is VERY SMART, uber handsome, and FRIGGI...  \n",
       "7                                  The book was good.  \n",
       "8                          The book was kind of good.  \n",
       "9   The plot was good, but the characters are unco...  \n",
       "10                 At least it isn't a horrible book.  \n",
       "11                      Make sure you :) or :D today!  \n",
       "12                                         Today SUX!  \n",
       "13         Today only kinda sux! But I'll get by, lol  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for sent in sentences:\n",
    "    score = sentiment.polarity_scores(sent)\n",
    "    scores.append(score)\n",
    "df = pd.DataFrame(scores)\n",
    "df['sentence'] = sentences\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate._\n",
    "\n",
    "> _It is also useful for researchers who would like to set standardized thresholds for classifying sentences as either positive, neutral, or negative._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>positive_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8316</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.746</td>\n",
       "      <td>VADER is smart, handsome, and funny.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.7424</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>VADER is not smart, handsome, nor funny.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.752</td>\n",
       "      <td>VADER is smart, handsome, and funny!</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.701</td>\n",
       "      <td>VADER is very smart, handsome, and funny.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.754</td>\n",
       "      <td>VADER is VERY SMART, handsome, and FUNNY.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>VADER is VERY SMART, handsome, and FUNNY!!!</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9469</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.706</td>\n",
       "      <td>VADER is VERY SMART, uber handsome, and FRIGGI...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.492</td>\n",
       "      <td>The book was good.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3832</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.343</td>\n",
       "      <td>The book was kind of good.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.7042</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.094</td>\n",
       "      <td>The plot was good, but the characters are unco...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.363</td>\n",
       "      <td>At least it isn't a horrible book.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8633</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.706</td>\n",
       "      <td>Make sure you :) or :D today!</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.5461</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Today SUX!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.251</td>\n",
       "      <td>Today only kinda sux! But I'll get by, lol</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    compound    neg    neu    pos  \\\n",
       "0     0.8316  0.000  0.254  0.746   \n",
       "1    -0.7424  0.646  0.354  0.000   \n",
       "2     0.8439  0.000  0.248  0.752   \n",
       "3     0.8545  0.000  0.299  0.701   \n",
       "4     0.9227  0.000  0.246  0.754   \n",
       "5     0.9342  0.000  0.233  0.767   \n",
       "6     0.9469  0.000  0.294  0.706   \n",
       "7     0.4404  0.000  0.508  0.492   \n",
       "8     0.3832  0.000  0.657  0.343   \n",
       "9    -0.7042  0.327  0.579  0.094   \n",
       "10    0.4310  0.000  0.637  0.363   \n",
       "11    0.8633  0.000  0.294  0.706   \n",
       "12   -0.5461  0.779  0.221  0.000   \n",
       "13    0.2228  0.179  0.569  0.251   \n",
       "\n",
       "                                             sentence  positive_sentiment  \n",
       "0                VADER is smart, handsome, and funny.                True  \n",
       "1            VADER is not smart, handsome, nor funny.               False  \n",
       "2                VADER is smart, handsome, and funny!                True  \n",
       "3           VADER is very smart, handsome, and funny.                True  \n",
       "4           VADER is VERY SMART, handsome, and FUNNY.                True  \n",
       "5         VADER is VERY SMART, handsome, and FUNNY!!!                True  \n",
       "6   VADER is VERY SMART, uber handsome, and FRIGGI...                True  \n",
       "7                                  The book was good.               False  \n",
       "8                          The book was kind of good.               False  \n",
       "9   The plot was good, but the characters are unco...               False  \n",
       "10                 At least it isn't a horrible book.               False  \n",
       "11                      Make sure you :) or :D today!                True  \n",
       "12                                         Today SUX!               False  \n",
       "13         Today only kinda sux! But I'll get by, lol               False  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['positive_sentiment'] = df['compound'] >= 0.5\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "I've read in a bunch of tweets from Trump, and stored them as a list of strings in `tweet_text`. Use the code from above to find the positive sentiment tweets and save them to a list called `positive_tweets`. Do the same for negative tweets, storing them in a variable called `negative_tweets`. What's the proportion of positive to negative tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today we express our deepest gratitude to all those who have served in our armed forces. #ThankAVet https://t.co/wPk7QWpK8Z',\n",
       " 'Busy day planned in New York. Will soon be making some very important decisions on the people who will be running our government!']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_fname = os.path.join(DATA_DIR, 'trump-tweets.csv')\n",
    "tweets = pd.read_csv(tweets_fname)\n",
    "tweet_text = list(tweets['Tweet_Text'].values)\n",
    "tweet_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets = []\n",
    "negative_tweets = []\n",
    "for tweet in tweet_text:\n",
    "    scores = sentiment.polarity_scores(tweet)\n",
    "    compound_score = scores['compound']\n",
    "    if compound_score >= 0.5:\n",
    "        positive_tweets.append(tweet)\n",
    "    elif compound_score <= -0.5:\n",
    "        negative_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7097127222982216\n"
     ]
    }
   ],
   "source": [
    "proportion = len(positive_tweets) / (len(positive_tweets) + len(negative_tweets))\n",
    "print(proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming <a id='stemming'></a>\n",
    "\n",
    "Stemming and lemmatization both refer to removing morphological affixes on words. For example, if we stem the word \"grows\", we get \"grow\". If we stem the word \"running\", we get \"run\". We do this because often we care more about the core content of the word (i.e. that it has something to do with growth or running, rather than the fact that it's a third person present tense verb, or progressive participle).\n",
    "\n",
    "NLTK provides many algorithms for stemming. For English, a great baseline is the [Porter algorithm](https://tartarus.org/martin/PorterStemmer/), which is in spirit isn't that far from a bunch of regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grow'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('grows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leav'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('leaves')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK has a variety of other stemming algorithms, and lemmatizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "snowball = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "eat\n",
      "embarass\n"
     ]
    }
   ],
   "source": [
    "print(snowball.stem('running'))\n",
    "print(snowball.stem('eats'))\n",
    "print(snowball.stem('embarassed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But watch out for errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cylind\n",
      "cylindr\n"
     ]
    }
   ],
   "source": [
    "# Thanks to Chris Hench for these examples\n",
    "print(snowball.stem('cylinder'))\n",
    "print(snowball.stem('cylindrical'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And collisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacat\n",
      "vacat\n"
     ]
    }
   ],
   "source": [
    "# Thanks to Chris Hench for these examples\n",
    "print(snowball.stem('vacation'))\n",
    "print(snowball.stem('vacate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacation\n",
      "vacate\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('vacation'))\n",
    "print(lemmatizer.lemmatize('vacate'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But why would you want to stem words in the first place? Well, stemming improves performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks again to Chris Hench for inspiration of this example\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about following along with this code, although it's great if you do!\n",
    "def read_data():\n",
    "    airline_fname = 'airline_tweets.csv'\n",
    "    airline_fname = os.path.join(DATA_DIR, airline_fname)\n",
    "    df = pd.read_csv(airline_fname)\n",
    "    twitter_handle_pattern = r'@(\\w+)'\n",
    "    hashtag_pattern = r'(?:^|\\s)[＃#]{1}(\\w+)'\n",
    "    url_pattern = r'https?:\\/\\/.*.com'\n",
    "    df['clean_text'] = (df['text']\n",
    "                        .str.replace(hashtag_pattern, 'HASHTAG')\n",
    "                        .str.replace(twitter_handle_pattern, 'USER')\n",
    "                        .str.replace(url_pattern, 'URL')\n",
    "                              )\n",
    "    text = list(df['clean_text'].str.lower())\n",
    "    sentiment = list(df['airline_sentiment'])\n",
    "    return text, sentiment\n",
    "\n",
    "def prepare_stems(sents):\n",
    "    snowball = SnowballStemmer('english')\n",
    "    tokenized_sents = [nltk.word_tokenize(s) for s in sents]\n",
    "    stemmed_sents = [[snowball.stem(s) for s in tokenized_sent] for tokenized_sent in tokenized_sents]\n",
    "    return [' '.join(sent) for sent in stemmed_sents]\n",
    "\n",
    "def prepare_no_stems(sents):\n",
    "    tokenized_sents = [nltk.word_tokenize(s) for s in sents]\n",
    "    return [' '.join(sent) for sent in tokenized_sents]\n",
    "\n",
    "def fit_model(X_train, y_train):\n",
    "    model = RandomForestClassifier(n_estimators=10, criterion='gini')                \n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def test_model(model, X_test, y_test):\n",
    "    print('Accuracy: ', model.score(X_test, y_test))\n",
    "\n",
    "def classify(sents, target):\n",
    "    vectorizer = TfidfVectorizer(max_features=5000, binary=True)\n",
    "    X = vectorizer.fit_transform(sents)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.25, random_state=42)\n",
    "    model = fit_model(X_train, y_train)\n",
    "    test_model(model, X_test, y_test)\n",
    "\n",
    "text, sentiment = read_data()\n",
    "stemmed_text = prepare_stems(text)\n",
    "unstemmed_text = prepare_no_stems(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7497267759562841\n"
     ]
    }
   ],
   "source": [
    "classify(stemmed_text, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.740983606557377\n"
     ]
    }
   ],
   "source": [
    "classify(unstemmed_text, sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we didn't cover <a id='didnt'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance\n",
    "\n",
    "NLTK has some functionality for calculating the distance between two strings. String distance is a measure of how different two strings are. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance('hello', 'helo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance('hello', 'hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of different ways to measure edit distance. This method uses Levenshtein distance, which is the number of insertions, deletions and substitutions required to turn one string into another. Edit distance is useful if you're looking for spelling mistakes.\n",
    "\n",
    "The [fuzzywuzzy library](https://github.com/seatgeek/fuzzywuzzy) does a great job of edit distance too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.16.0-py2.py3-none-any.whl\n",
      "Installing collected packages: fuzzywuzzy\n",
      "  Found existing installation: fuzzywuzzy 0.15.1\n",
      "    Uninstalling fuzzywuzzy-0.15.1:\n",
      "      Successfully uninstalled fuzzywuzzy-0.15.1\n",
      "Successfully installed fuzzywuzzy-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'this is a test' == 'this is a test!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "fuzz.ratio('this is a test', 'this is a test!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation\n",
    "\n",
    "NLTK offers [some tools](https://github.com/nltk/nltk/tree/develop/nltk/translate) for machine translation. This is great for learning traditional translation models, but is out-dated. If you actually need to translate some text, currently I'd highly using the [Google Translate API](https://cloud.google.com/translate/docs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification\n",
    "\n",
    "NLTK has [support for text classification](https://github.com/nltk/nltk/tree/develop/nltk/classify) using machine learning. However, I'd recommend using [scikit-learn](http://scikit-learn.org/stable/), [TensorFlow](https://www.tensorflow.org/) or [Keras](https://keras.io/) for this now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbots\n",
    "\n",
    "These are mainly just for fun. But check out the [source code](https://github.com/nltk/nltk/tree/develop/nltk/chat) if you're ever interested in building a simple chatbot yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work so well in a Jupyter notebook because it requires interaction,\n",
    "# but try it in a terminal or IDE!\n",
    "#nltk.chat.chatbots()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
